# Application de PrÃ©diction de Sentiments

## ğŸ“– Objectif du Projet
Ce projet vise Ã  dÃ©velopper une **API de prÃ©diction de sentiments** pour analyser le ton des tweets. L'objectif est d'expÃ©rimenter diffÃ©rentes approches de modÃ©lisation NLP et d'intÃ©grer une dÃ©marche **MLOps** complÃ¨te.

- **ModÃ¨le sur mesure simple** : RÃ©gression Logistique avec TF-IDF
- **ModÃ¨le sur mesure avancÃ©** : LSTM avec embeddings
- **ModÃ¨le avancÃ© BERT** : Fine-tuning dâ€™un modÃ¨le BERT
- **Tracking et gestion des modÃ¨les** avec **MLFlow**
- **DÃ©ploiement continu** via **GitHub Actions**
- **Interface de test utilisateur** avec **Streamlit**
- **Monitoring en production** via **Azure Application Insights**

## ğŸ—ï¸ Structure du Projet

```
ğŸ“‚ tweet_classifier_app-main/
â”œâ”€â”€ ğŸ“œ .gitignore
â”œâ”€â”€ ğŸ“œ app.py               # Interface utilisateur avec Streamlit
â”œâ”€â”€ ğŸ“œ main.py              # API FastAPI pour la prÃ©diction et le feedback
â”œâ”€â”€ ğŸ“œ requirements.txt      # Liste des dÃ©pendances
â”œâ”€â”€ ğŸ“œ startup.sh            # Script de lancement (API + Streamlit)
â”œâ”€â”€ ğŸ“‚ model/                # Contient les modÃ¨les entraÃ®nÃ©s (Logistic Regression, LSTM, BERT)
â”‚   â”œâ”€â”€ logistic_regression_model.pkl
â”œâ”€â”€ ğŸ“‚ vectorizer/           # Contient le vectorizer TF-IDF
â”‚   â”œâ”€â”€ vectorizer.pkl
â”œâ”€â”€ ğŸ“‚ tests/                # Contient les tests unitaires pour valider les fonctionnalitÃ©s de l'API
â”‚   â”œâ”€â”€ test_main.py
â”œâ”€â”€ ğŸ“‚ .github/workflows/    # Pipeline CI/CD avec GitHub Actions
â”‚   â”œâ”€â”€ main_tweet-classifier-app.yml
```

## ğŸš€ Installation & Lancement
### 1ï¸âƒ£ Cloner le projet
```bash
git clone <repo_url>
cd tweet_classifier_app-main
```

### 2ï¸âƒ£ Installer les dÃ©pendances
```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ Lancer lâ€™API et lâ€™interface utilisateur
Le lancement se fait via **startup.sh** qui dÃ©marre Ã  la fois l'API et l'interface Streamlit.

```bash
bash startup.sh
```

Ce script exÃ©cute :
- **FastAPI avec Gunicorn** en arriÃ¨re-plan sur le port **8001**
- **Streamlit** sur le port **8000**

## ğŸ”— Endpoints de l'API
| MÃ©thode | Endpoint         | Description |
|---------|----------------|-------------|
| POST    | `/predict`     | Envoie un tweet et retourne la prÃ©diction du sentiment |
| POST    | `/feedback`    | Enregistre le feedback de lâ€™utilisateur sur la prÃ©diction |

## ğŸ“¦ Packages UtilisÃ©s
Le projet repose sur plusieurs bibliothÃ¨ques essentielles :

- **Framework Web & API** : `FastAPI`, `uvicorn`, `gunicorn`, `httpx`
- **Manipulation des donnÃ©es** : `numpy`, `pandas`, `scikit-learn`
- **Machine Learning & NLP** : `transformers`, `torch`
- **Interface utilisateur** : `streamlit`
- **Gestion des modÃ¨les & logs** : `MLFlow`
- **Monitoring & ObservabilitÃ©** : `opencensus-ext-azure`, `opencensus`, `opencensus-ext-logging`, `opencensus-ext-flask`, `opencensus-ext-requests`
- **Tests et validation** : `pytest`, `pydantic`

## ğŸ”„ DÃ©ploiement AutomatisÃ© (CI/CD)
Le projet intÃ¨gre un **pipeline CI/CD avec GitHub Actions** qui permet :
- **ExÃ©cution automatique des tests unitaires** avec pytest Ã  chaque commit.
- **DÃ©ploiement automatique** de lâ€™API et de lâ€™interface utilisateur sur un service Cloud.
- **Surveillance en production** avec **Azure Application Insights** pour remonter les erreurs.

## ğŸ“Š Suivi des Performances en Production
- **MLFlow** est utilisÃ© pour tracker les modÃ¨les et comparer leurs performances.
- **Azure Application Insights** dÃ©tecte les tweets mal prÃ©dits et dÃ©clenche des alertes.
- Un **systÃ¨me dâ€™alerte** est configurÃ© pour envoyer un e-mail/SMS en cas de problÃ¨me.
